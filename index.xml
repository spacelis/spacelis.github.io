<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SpaceLi&#39;s Blog</title>
    <link>https://spacelis.github.io/index.xml</link>
    <description>Recent content on SpaceLi&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Dec 2016 09:02:19 +0000</lastBuildDate>
    <atom:link href="https://spacelis.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>CSV-Loader</title>
      <link>https://spacelis.github.io/post/csv-loader/</link>
      <pubDate>Fri, 09 Dec 2016 09:02:19 +0000</pubDate>
      
      <guid>https://spacelis.github.io/post/csv-loader/</guid>
      <description>

&lt;p&gt;My work requires me importing a variety tables from CSV to DBMS.
However, importing CSV is not always an easy and documentable task, as every DBMS has its own way of doing the job.
There are different tools, be it GUI or CUI, that can help the process but there lacks a tool generally available for the task.
I needed a tool for importing CSV tables and I took this opportunity to make a general tool.&lt;/p&gt;

&lt;h1 id=&#34;csv-loader&#34;&gt;CSV-Loader&lt;/h1&gt;

&lt;p&gt;CSV-Loader uses SQLAlchemy for generalize the DB operating and messytables for schema detecting.
The tool is composed of several commands, one is for generating schemas from arbitrary CSV files.
Another is for uploading the data according to the schema generated.
The third is for building single column indices for all columns on a table.&lt;/p&gt;

&lt;h1 id=&#34;schema-as-documentation&#34;&gt;Schema As Documentation&lt;/h1&gt;

&lt;p&gt;The schema generated from the CSV is an intermediate step for importing the CSV files.
It gives users a chance to review the schema before importing millions of rows for a few hours.
Sometimes, simple data type conversion or transformation is needed during the importing.
Thus users can edit the schema file to integrate the conversion or transformation into the importing processes.
In these cases, the schema file can be archived for data documentation, so that when there is similar data required to be imported, the same processes can be reused to ensure the consistance.&lt;/p&gt;

&lt;h1 id=&#34;implementation-details&#34;&gt;Implementation Details&lt;/h1&gt;

&lt;p&gt;For CSV-Loader, &lt;code&gt;messytables&lt;/code&gt; is used for detecting the types and names of columns in a CSV file.
Accordingly, the schema is generated in pure Python module.
The schema generating tool will also try to convert column names into a format that will comply with the naming rules in the DB.
When column names are missing in the CSV file, users are required to edit the schema file to assign a name to each column.
Otherwise, the tool may fail importing data into the DB.
This will be improved in the future release.
For example, some random name will be generated to enable importing before naming.&lt;/p&gt;

&lt;p&gt;Currently, enabled by &lt;code&gt;SQLAlchemy&lt;/code&gt;, CSV-Loader supports four different RDBMS, that is, SQLite, MySQL, PostgreSQL, MSSQL.
Since only a small set of language is used in the importing process, a later version of CSV-Loader may integrate non-SQL DB importing.
Hopefull, it can help users that requires different DBMS in their data analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BakMan: A file oriented backup management tool.</title>
      <link>https://spacelis.github.io/post/bakman/</link>
      <pubDate>Wed, 02 Nov 2016 22:17:59 +0000</pubDate>
      
      <guid>https://spacelis.github.io/post/bakman/</guid>
      <description>

&lt;p&gt;If you ever had tons of backup files which quickly fill up all your disk space, this tool might be useful to you.
Bakman is a BAcKup MANagement tool for automatically tracing unneeded backup files and generating management scripts.
The core idea is to filtering backup files by a set of customizable rules.
The rule file will define which files in the piles should be removed or stashed somewhere else.&lt;/p&gt;

&lt;h1 id=&#34;bakman&#34;&gt;BakMan&lt;/h1&gt;

&lt;p&gt;This project was originate from my needs to manage the backup files of a website.
The website provides access to quite some datasets which took a lot of place to backup at daily frequency.
It triggered me to thing about the general way of dealing with backup files when the disk was incidently filled up and got the website down.
Therefore I have to delete some backup files to release disk space for running the website.
However, deleting all the backup files up to a certain date is kind of simple and effective way but you may loose the trace and may cause you in trouble if you are not frequently managing the website.
So it might be better to have a tool that allows you to use more complex logic for managing your backups.
For example, you may want to keep all the backups within 7 days and one per week within 3 months and one per month for those older than 3 months.
This logic will greatly reduce the number of backups you need to keep and still give you the ability of tracing the changes since the very beginning.
The downside is that I need to write the tool as I could not find a suitable ones on the Internet.
Maybe I am just curious about whether I can build one myself and there you go BakMan.&lt;/p&gt;

&lt;h1 id=&#34;script-generating-vs-action-immediately&#34;&gt;Script Generating VS action immediately&lt;/h1&gt;

&lt;p&gt;BakMan accepts a rule file defining how the backup files should be separated, that is, those that need to be deal with and those that should be left untouched.
Based on the rules, BakMan will generate a script by feeding those that need to be dealt with into a template.
For example, if you use &lt;code&gt;rm -rf {0}&lt;/code&gt;, then the script will try to remove all the unwanted backup files.
If you use &lt;code&gt;trash {0}&lt;/code&gt;, then the script will put unwanted backup files in the trash can.
An alternative design could be carry out actions immediately without generating a script for user to run.
But making dangeous actions as default is never a good idea.
So giving users a chance to inspect the actual actions that are going to carry out will make sure they are not suprised.
Of course users can still automate the task by piping the output script to bash.
This little extra effort and the delibration asking users to think twice will reduce the chance of going to a disaster.
Similar design can be found every where from querying user when &lt;code&gt;rm&lt;/code&gt; a file to requesting user to type repository name when deleting it on Github.
It also allows trial run with no harm to the system.&lt;/p&gt;

&lt;h1 id=&#34;the-rule-system&#34;&gt;The Rule System&lt;/h1&gt;

&lt;p&gt;The core of BakMan is the rule system, which make it a nice tool for complex backup retaining strategy.
The rule system is based on group-aware marking.
Simple as it is, it marks files based on its role in a group.
The group can be defined by a period of time, for example, a month or a week.
A role in a group can be the first one in the group or the last one.
The markings from different group can either be merged in a conjunction way or a disjunction way.&lt;/p&gt;

&lt;p&gt;The rules are organized in a tree structure as different level of mark merging may be required.
In BakMan, the rule file can be written in YAML or JSON.
A parser will translate it into a tree structure of makers.
This marker will be applied to the files that need to be managed.&lt;/p&gt;

&lt;h1 id=&#34;an-extensible-tool&#34;&gt;An Extensible Tool&lt;/h1&gt;

&lt;p&gt;Along with developing the rule parser, quite some effort was put into the extensibility of the parsers.
The parser is integrated to the markers which a metaclass is created to allow implicit registering of new markers.
Following the pattern, one can easily create a new marker and it will automatically be integrated into the rule system.&lt;/p&gt;

&lt;h1 id=&#34;last-words&#34;&gt;Last Words&lt;/h1&gt;

&lt;p&gt;This is a tool purely for my own interests.
I hope it can become useful for some of you.
Please let me know you if it helps you.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>hello world</title>
      <link>https://spacelis.github.io/post/hello-world/</link>
      <pubDate>Thu, 27 Oct 2016 22:38:35 +0100</pubDate>
      
      <guid>https://spacelis.github.io/post/hello-world/</guid>
      <description>&lt;p&gt;I just start use (again) the github pages for my blog. Hopefully I will write more from now on.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>